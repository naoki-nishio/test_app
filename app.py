import streamlit as st
import streamlit_authenticator as stauth
import pandas as pd
import numpy as np
import pickle
import os
from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer
import warnings
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å…¥æœ­å‚åŠ äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ—ï¸"
)

# èªè¨¼è¨­å®šï¼ˆStreamlit Secretsã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
def setup_authentication():
    """Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿"""
    try:
        # Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        credentials = dict(st.secrets["credentials"])
        
        authenticator = stauth.Authenticate(
            credentials,
            st.secrets["auth"]["cookie_name"],
            st.secrets["auth"]["cookie_key"], 
            cookie_expiry_days=st.secrets["auth"]["cookie_expiry_days"]
        )
        
        return authenticator
    except KeyError as e:
        st.error(f"èªè¨¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.error("ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„")
        return None
    except Exception as e:
        st.error(f"èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# èªè¨¼å‡¦ç†
authenticator = setup_authentication()
if authenticator is None:
    st.stop()

name, authentication_status, username = authenticator.login('ãƒ­ã‚°ã‚¤ãƒ³', 'main')

if authentication_status == False:
    st.error('ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™')
elif authentication_status == None:
    st.warning('ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„')
elif authentication_status:
    # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸæ™‚ã®å‡¦ç†
    
    # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³
    authenticator.logout('ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ', 'sidebar')
    st.sidebar.write(f'ã‚ˆã†ã“ã *{name}* ã•ã‚“')
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ—ï¸ å…¥æœ­å‚åŠ äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›´ï¼‰
    MODEL_FOLDER = "models_2"
    DATA_PATH = "å…¥æœ­ãƒ‡ãƒ¼ã‚¿_å‡¦ç†æ¸ˆã¿.csv"
    
    # å¯¾è±¡ä¼æ¥­ãƒªã‚¹ãƒˆ
    target_companies = [
        'é‡‘æœ¬å»ºè¨­ï¼ˆæ ªï¼‰', 'åŒ—æ²¢å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæ ªï¼‰ã‚«ãƒªã‚¹', 'å—ä¿¡åœŸæœ¨å»ºç¯‰ï¼ˆæœ‰ï¼‰', 
        'ç¥ç¨²å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæ ªï¼‰ãƒ‘ãƒ†ãƒƒã‚¯', 'ï¼ˆæ ªï¼‰ä¸‰å…­çµ„', 'ï¼ˆæ ªï¼‰ãƒˆãƒ©ã‚¤ãƒãƒƒãƒˆ',
        'ï¼ˆæœ‰ï¼‰åŒ—åŸåœŸæœ¨', 'æœ¨ä¸‹å·¥æ¥­ï¼ˆæ ªï¼‰', 'ã‚¯ãƒ©ã‚¦ãƒ‹ãƒ³ã‚°ï¼ˆæ ªï¼‰', 'æœ¨ä¸‹å»ºè¨­ï¼ˆæ ªï¼‰',
        'ç´°æ¾¤å»ºè¨­ï¼ˆæ ªï¼‰', 'å°æœ¨æ›½å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæ ªï¼‰æ¸…ä¿¡å»ºè¨­èˆˆæ¥­', 'ï¼ˆæ ªï¼‰ã‚·ãƒãƒ€',
        'å°æ± å»ºè¨­ï¼ˆæ ªï¼‰', 'å®®å˜‰å»ºè¨­ï¼ˆæœ‰ï¼‰', 'å‰å·å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæœ‰ï¼‰ç¦å£«çµ„',
        'é•·è±Šå»ºè¨­ï¼ˆæ ªï¼‰', 'é“æ „å»ºè¨­ï¼ˆæ ªï¼‰', 'ä¼Šè³€è‰¯å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæœ‰ï¼‰ç•‘ä¸­å·¥å‹™æ‰€',
        'ï¼ˆæ ªï¼‰å°¾ç•‘çµ„', 'ï¼ˆæœ‰ï¼‰ä»Šæ‘å·¥å‹™æ‰€', 'é˜¿æ™ºå·¥å‹™åº—ï¼ˆæ ªï¼‰', 'å‹é–“ç”°å»ºè¨­ï¼ˆæ ªï¼‰',
        'å¤ç”°å·¥æ¥­ï¼ˆæ ªï¼‰', 'å¤§å”å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæ ªï¼‰ä¸‹å¹³çµ„', 'ä¸‰å»ºå»ºè¨­ï¼ˆæœ‰ï¼‰',
        'é«˜æœ¬å»ºè¨­ï¼ˆæ ªï¼‰', 'ï¼ˆæœ‰ï¼‰æ–°é‡å·¥å‹™åº—', 'ï¼ˆæœ‰ï¼‰ç«¹æ‘å·¥å‹™æ‰€', 'ï¼ˆæ ªï¼‰ã‚µãƒ³ãƒ†ã‚¯ãƒˆ',
        'ï¼ˆæ ªï¼‰å‰é‡çµ„', 'å¤ªç”°åœŸå»ºï¼ˆæœ‰ï¼‰', 'æ± ç«¯å·¥æ¥­ï¼ˆæ ªï¼‰', 'ï¼ˆæ ªï¼‰è¿‘è—¤å·¥å‹™åº—',
        'çŸ¢æœ¨ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ ªï¼‰', 'ï¼ˆæœ‰ï¼‰æ–°äº•å·¥å‹™åº—', 'å…±æ­©ï¼ˆæ ªï¼‰', 'è—¤äº•èˆˆæ¥­ï¼ˆæ ªï¼‰',
        'å—éƒ¨å»ºè¨­ï¼ˆæœ‰ï¼‰', 'å®®ä¸‹å»ºè¨­ï¼ˆæœ‰ï¼‰', 'ï¼ˆæ ªï¼‰é‡‘ç”°çµ„', 'å¤§å¹³å»ºè¨­ï¼ˆæ ªï¼‰',
        'ï¼ˆæœ‰ï¼‰é›„é•·çµ„', 'ï¼ˆæ ªï¼‰å—å»ºè¨­', 'é•·é‡æ©Ÿæï¼ˆæ ªï¼‰', 'å±±å´å»ºè¨­ï¼ˆæ ªï¼‰',
        'ï¼ˆæ ªï¼‰ç‰‡æ¡å·¥å‹™æ‰€', 'ï¼ˆæœ‰ï¼‰ãƒ’ãƒ©ã‚µãƒ¯', 'ï¼ˆæœ‰ï¼‰ã‚¤ãƒãƒåœŸæœ¨', 'ï¼ˆæœ‰ï¼‰å°¾ç•‘çµ„',
        'é£¯ä¼Šæ£®æ—çµ„åˆ'
    ]

    def get_probability_level(probability):
        """ç¢ºç‡ã‚’äºˆæ¸¬ã¨ç¢ºç‡ãƒ¬ãƒ™ãƒ«ã«å¤‰æ›ã™ã‚‹"""
        if probability < 0.5:
            return "ä¸å‚åŠ ", "ä½", 0
        elif probability < 0.75:
            return "å‚åŠ ", "ä¸­", 1
        else:
            return "å‚åŠ ", "é«˜", 2

    @st.cache_data
    def load_encoders():
        """äº‹å‰å­¦ç¿’æ¸ˆã¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(os.path.join(MODEL_FOLDER, 'mlb_type.pkl'), 'rb') as f:
                mlb_type = pickle.load(f)
            
            with open(os.path.join(MODEL_FOLDER, 'mlb_summary.pkl'), 'rb') as f:
                mlb_summary = pickle.load(f)
            
            with open(os.path.join(MODEL_FOLDER, 'ohe.pkl'), 'rb') as f:
                ohe = pickle.load(f)
            
            return mlb_type, mlb_summary, ohe
        except Exception as e:
            st.error(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, None

    def load_company_model(company_name):
        """ä¼æ¥­åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        model_filename = f"{company_name.replace('/', '_').replace('ï¼ˆ', '(').replace('ï¼‰', ')')}_smote_xgboost.pkl"
        model_path = os.path.join(MODEL_FOLDER, model_filename)
        
        if not os.path.exists(model_path):
            return None
        
        try:
            with open(model_path, 'rb') as f:
                model = pickle.load(f)
            return model
        except:
            return None

    def create_feature_vector(bidding_method, agency, location, qualification_score, 
                             planned_price, work_type, work_summary, mlb_type, mlb_summary, ohe):
        """ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ"""
        try:
            # æ•°å€¤ç‰¹å¾´é‡
            X_num = np.array([qualification_score, planned_price])
            
            # å·¥ç¨®ãƒ»å·¥äº‹æ¦‚è¦
            work_type_list = [str(work_type).split('ãƒ»')]
            summary_list = [str(work_summary).split()]
            
            X_type = mlb_type.transform(work_type_list)
            X_summary = mlb_summary.transform(summary_list)
            
            # ã‚«ãƒ†ã‚´ãƒª
            cat_data = pd.DataFrame({
                'å…¥æœ­æ–¹å¼': [bidding_method],
                'ç™ºæ³¨æ©Ÿé–¢': [agency],
                'å·¥äº‹å ´æ‰€': [location]
            })
            X_cat = ohe.transform(cat_data)
            
            # ç‰¹å¾´é‡çµåˆ
            X = np.hstack([X_num, X_type.flatten(), X_summary.flatten(), X_cat.flatten()])
            return X
        except Exception as e:
            st.error(f"ç‰¹å¾´é‡ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿
    mlb_type, mlb_summary, ohe = load_encoders()

    if mlb_type is None:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        st.stop()

    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    st.header("æ¡ˆä»¶æƒ…å ±å…¥åŠ›")

    col1, col2 = st.columns(2)

    with col1:
        bidding_method = st.text_input("å…¥æœ­æ–¹å¼", value="")
        agency = st.text_input("ç™ºæ³¨æ©Ÿé–¢", value="")
        location = st.text_input("å·¥äº‹å ´æ‰€", value="")

    with col2:
        qualification_score = st.number_input("è³‡æ ¼ç‚¹æ•°", min_value=0, max_value=1500, value=0)
        planned_price = st.number_input("äºˆå®šä¾¡æ ¼ï¼ˆå††ï¼‰", min_value=0, value=0, step=1000000)
        work_type = st.text_input("å·¥ç¨®", value="")

    work_summary = st.text_area("å·¥äº‹æ¦‚è¦", value="", height=100)

    # äºˆæ¸¬å®Ÿè¡Œ
    if st.button("äºˆæ¸¬å®Ÿè¡Œ"):
        
        # ç‰¹å¾´é‡ä½œæˆ
        features = create_feature_vector(
            bidding_method, agency, location, qualification_score,
            planned_price, work_type, work_summary, mlb_type, mlb_summary, ohe
        )
        
        if features is None:
            st.error("ç‰¹å¾´é‡ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            st.stop()
        
        # äºˆæ¸¬å®Ÿè¡Œ
        predictions = []
        
        for company in target_companies:
            model = load_company_model(company)
            
            if model is not None:
                try:
                    features_2d = features.reshape(1, -1)
                    prediction = model.predict(features_2d)[0]
                    probability = model.predict_proba(features_2d)[0][1]
                    
                    prediction_result, prob_level, sort_key = get_probability_level(probability)
                    
                    predictions.append({
                        'ä¼æ¥­å': company,
                        'äºˆæ¸¬': prediction_result,
                        'ç¢ºç‡ãƒ¬ãƒ™ãƒ«': prob_level,
                        'å‚åŠ ç¢ºç‡': f"{probability:.1%}",  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¡¨ç¤º
                        'ã‚½ãƒ¼ãƒˆã‚­ãƒ¼': sort_key,
                        'ç¢ºç‡æ•°å€¤': probability
                    })
                except:
                    predictions.append({
                        'ä¼æ¥­å': company,
                        'äºˆæ¸¬': 'ã‚¨ãƒ©ãƒ¼',
                        'ç¢ºç‡ãƒ¬ãƒ™ãƒ«': '-',
                        'å‚åŠ ç¢ºç‡': '-',
                        'ã‚½ãƒ¼ãƒˆã‚­ãƒ¼': -1,
                        'ç¢ºç‡æ•°å€¤': 0
                    })
            else:
                predictions.append({
                    'ä¼æ¥­å': company,
                    'äºˆæ¸¬': 'ãƒ¢ãƒ‡ãƒ«ãªã—',
                    'ç¢ºç‡ãƒ¬ãƒ™ãƒ«': '-',
                    'å‚åŠ ç¢ºç‡': '-',
                    'ã‚½ãƒ¼ãƒˆã‚­ãƒ¼': -1,
                    'ç¢ºç‡æ•°å€¤': 0
                })
        
        # çµæœè¡¨ç¤ºï¼ˆç¢ºç‡æ•°å€¤ã§ã‚½ãƒ¼ãƒˆï¼‰
        results_df = pd.DataFrame(predictions)
        results_df = results_df.sort_values('ç¢ºç‡æ•°å€¤', ascending=False)
        
        st.header("äºˆæ¸¬çµæœ")
        
        # ã‚µãƒãƒªãƒ¼
        participating = results_df[results_df['äºˆæ¸¬'] == 'å‚åŠ ']
        high_prob = results_df[results_df['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'é«˜']
        medium_prob = results_df[results_df['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'ä¸­']
        low_prob = results_df[results_df['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'ä½']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å‚åŠ äºˆæ¸¬ä¼æ¥­æ•°", len(participating))
        with col2:
            st.metric("ç¢ºç‡é«˜ (75%ä»¥ä¸Š)", len(high_prob))
        with col3:
            st.metric("ç¢ºç‡ä¸­ (50-75%)", len(medium_prob))
        with col4:
            st.metric("ç¢ºç‡ä½ (50%æœªæº€)", len(low_prob))
        
        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆç¢ºç‡æ•°å€¤ã‚’å«ã‚€ï¼‰
        display_df = results_df[['ä¼æ¥­å', 'äºˆæ¸¬', 'ç¢ºç‡ãƒ¬ãƒ™ãƒ«', 'å‚åŠ ç¢ºç‡']].copy()
        
        # ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã‚’é©ç”¨ï¼ˆç¢ºç‡ãŒé«˜ã„é †ã«è‰²åˆ†ã‘ï¼‰
        def highlight_probability(row):
            if row['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'é«˜':
                return ['background-color: #ffebee'] * len(row)
            elif row['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'ä¸­':
                return ['background-color: #fff3e0'] * len(row)
            elif row['ç¢ºç‡ãƒ¬ãƒ™ãƒ«'] == 'ä½':
                return ['background-color: #f3e5f5'] * len(row)
            else:
                return [''] * len(row)
        
        styled_df = display_df.style.apply(highlight_probability, axis=1)
        st.dataframe(styled_df, use_container_width=True, height=400)